{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN\n",
    "\n",
    "def distance(x1,x2):\n",
    "    \n",
    "    return np.sqrt(((x1-x2)**2).sum())\n",
    "\n",
    "def knnPred(trainData , testPt , k=5):\n",
    "    \n",
    "    distVals = []\n",
    "    for i in range(trainData.shape[0]):\n",
    "        \n",
    "        ix = trainData[i,:-1]\n",
    "        iy = trainData[i,-1]\n",
    "        \n",
    "        d = distance(ix , testPt)\n",
    "        distVals.append((d,iy))\n",
    "        \n",
    "    distVals = sorted(distVals , key=lambda x:x[0])\n",
    "    distVals = distVals[:k]\n",
    "    \n",
    "    labels = np.array(distVals)[:,-1]\n",
    "    output = np.unique(labels , return_counts=True)\n",
    "    \n",
    "    index = output[1].argmax()\n",
    "    pred = output[0][index]\n",
    "    \n",
    "    return pred\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#FaceDetection\n",
    "faceCascades = cv2.CascadeClassifier('/Volumes/part3/haarcascades_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 0 \n",
    "datasetPath = '/Volumes/part3/faceRecogDataSet/'\n",
    "\n",
    "faceData = []  # x value for our data\n",
    "labels = []     # y value for our data\n",
    "\n",
    "classID = 0\n",
    "names = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Amit.npy\n",
      "(30, 30000)\n",
      "Loaded Mitul.npy\n",
      "(30, 30000)\n",
      "Loaded Pranav.npy\n",
      "(30, 30000)\n"
     ]
    }
   ],
   "source": [
    "for fx in os.listdir(datasetPath):\n",
    "    \n",
    "    if (fx.endswith('.npy')):\n",
    "        \n",
    "        #Create a mapping between classID and corresponding name.\n",
    "        names[classID] = fx[:-4]  \n",
    "        \n",
    "        \n",
    "        #extract data from file\n",
    "        dataItem = np.load(datasetPath+fx)\n",
    "        print(\"Loaded \"+fx)\n",
    "        print(dataItem.shape)\n",
    "        faceData.append(dataItem)\n",
    "        \n",
    "        curlabel = classID*np.ones((dataItem.shape[0],))\n",
    "        # for every image captured(training data) we have a corresponding label\n",
    "        \n",
    "        classID+=1\n",
    "        labels.append(curlabel)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 30, 30000)\n",
      "(3, 30)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(faceData).shape)\n",
    "print(np.array(labels).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDataSet = np.concatenate(faceData , axis=0)\n",
    "faceLabels = np.concatenate(labels , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 30000)\n",
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "print(faceDataSet.shape)\n",
    "print(faceLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1],\n",
       "       [4, 5, 6, 2],\n",
       "       [7, 8, 9, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try\n",
    "\n",
    "a = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "\n",
    "b = np.array([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "np.concatenate((a,b),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 30001)\n"
     ]
    }
   ],
   "source": [
    "# clubbing the facedataset and facelabels in a single matrix to use it in KNN algorithm.\n",
    "\n",
    "faceLabels = faceLabels.reshape((-1,1))\n",
    "trainDataSet = np.concatenate((faceDataSet , faceLabels), axis = 1)\n",
    "print(trainDataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing part\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret , frame = cap.read()\n",
    "    if (ret == False):\n",
    "        continue\n",
    "        \n",
    "    faces = faceCascades.detectMultiScale(frame , 1.3 , 5)\n",
    "    \n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        offset = 10\n",
    "        faceSection = frame[y-offset:y+h+offset , x-offset:x+w+offset]\n",
    "        faceSection = cv2.resize(faceSection,(100,100))\n",
    "        \n",
    "        # Our prediction.\n",
    "        predID = knnPred(trainDataSet , faceSection.flatten())\n",
    "        \n",
    "        \n",
    "        #Display on screen name and rectangle around it.\n",
    "        \n",
    "        predName = names[int(predID)]\n",
    "        cv2.putText(frame , predName , (x,y-10) ,  cv2.FONT_HERSHEY_PLAIN,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Video Capture\",frame)\n",
    "     \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if (key == ord('q')):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
